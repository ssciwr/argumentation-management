{   
  "title": "Main input options",
  "properties": {
    "input": {
        "default": "input.txt",
        "title": "Input file:",
        "type": "string"
    },
    "tool": {
      "default": "spacy",
      "title": "Tool used for annotation:",
      "type": "string"
  },
    "corpus_name": {
      "default": "test",
      "title": "Name of corpus to be annotated:",
      "type": "string"
    },
    "language": {
      "default": "en",
      "enum": [
        "en",
        "de",
        "ar",
        "be",
        "fr",
        "it",
        "ja",
        "pt",
        "ru",
        "es",
        "uk"
      ],
      "title": "Document language:",
      "type": "string"
    },
    "processing_option": {
      "default": "fast",
      "enum": [
        "fast",
        "accurate",
        "manual"
      ],
      "title": "Processing preference for toolchain selection:",
      "type": "string"
    },
    "processing_type": {
      "default": "tokenize",
      "title": "Annotation type:",
      "type": "string"
    },
    "encoding": {
      "default": "no",
      "enum": [
        "yes",
        "no"
      ],
      "title": "Encode produced text file into cwb",
      "type": "string"
    }
  },
  "advanced_options": {
    "properties": {
      "output_dir": {
        "default": "out/",
        "title": "Output directory:",
        "type": "string"
      },
      "output_format": {
        "default": "vrt",
        "title": "Output file format:",
        "type": "string"
      },
      "corpus_dir": {
        "default": "corpora/",
        "title": "Name of corpora directory for cwb:",
        "type": "string"
      },
      "registry_dir": {
        "default": "registry/",
        "title": "Name of registry directory for cwb:",
        "type": "string"
      },
      "multiprocessing": {
        "default": false,
        "title": "Run on multiple processors:",
        "type": "boolean" 
      },
      "use_GPU": {
        "default": false,
        "title": "Run on GPUs:",
        "type": "boolean" 
      },
    "title": "Advanced input options",
    "type": "object"
  },
  "tooldict": {
    "anyOf": [
      {
        "properties": {
          "lang": {
            "default": "en",
            "description": "Language code for the language to build the Pipeline in",
            "enum": [
              "en",
              "de"
            ],
            "title": "Language",
            "type": "string"
          },
          "dir": {
            "default": "./test/models",
            "description": "Directory where models are stored - this maynot work for pipeline",
            "title": "Model directory:",
            "type": "string"
          },
          "package": {
            "default": "default",
            "description": "Using the default model, for others see: https://stanfordnlp.github.io/stanza/models.html",
            "title": "Model to use:",
            "type": "string"
          },
          "processors": {
            "default": [],
            "description": "Comma-separated list of processors to use, can also be given as a dictionary: {'tokenize': 'ewt', 'pos': 'ewt'}",
            "title": "Processors to use:",
            "type": "list"
          },
          "logging_level": {
            "default": "INFO",
            "description": "DEBUG, INFO, WARN, ERROR, CRITICAL, FATAL; FATAL has least amount of log info printed",
            "title": "Level of logging:",
            "type": "string"
          },
          "verbose": {
            "default": true,
            "description": "True corresponds to INFO, False corresponds to ERROR",
            "title": "Verbose? (True corresponds to INFO, False corresponds to ERROR)",
            "type": "boolean" 
          },
          "type": {
            "const": "stanza",
            "type": "string"
          },
          "use_GPU": {
            "default": false,
            "description": "Use GPU if available, False forces CPU only",
            "title": "Use GPU (Use GPU if available, False forces CPU only)",
            "type": "boolean"
          },
          "stanza_tokenize": {
            "properties": {
              "tokenize_batch_size": {
                  "default": 32,
                  "description": "Maximum number of paragraphs to process as minibatch for efficient processing",
                  "title": "Tokenize batch size",
                  "type": "integer",
                  "minimum": 1
              },
              "tokenize_no_ssplit": {
                  "default": false,
                  "description": "",
                  "title": "Toggle tokenize no-split.",
                  "type": "boolean"
              }
            },
            "description": "Tokenizes the text and performs sentence segmentation, dependency: -",
            "title": "Stanza Tokenizer",
            "type": "object"
          },
          "stanza_mwt": {
            "properties": {
              "mwt_batch_size": {
                "default": 50,
                "description": " Specifies maximum number of words to process as a minibatch",
                "title": "Number of words to process per minibatch.",
                "type": "integer",
                "minimum": 1
              }
            },
            "description": "Expands multi-word tokens (MWT) predicted by the TokenizeProcessor, this is only applicable to some languages, dependency: - 'tokenize'",
            "title": "Stanza multi-word tokens",
            "type": "object"
          },
          "stanza_lemma" : {
            "properties": {
              "lemma_use_identity": {
                "default": false,
                "description": "Identity lemmatizer is used instead of statistical lemmatizer",
                "title": "Toggle identity lemmatizer",
                "type": "boolean"
              },
              "lemma_batch_size": {
                "default": 50,
                "description": "Maximum number of words to batch for efficient processing. Default: 50",
                "title": "Lemmatizer batch size",
                "type": "integer",
                "minimum": 1
              },
              "lemma_ensemble_dict": {
                "default": true,
                "description": "Lemmatizer will ensemble a seq2seq model with output from dictionary-based lemmatizer, improvement for many languages",
                "title": "Enable seq2seq model",
                "type": "boolean"
              },
              "lemma_dict_only": {
                "default": true,
                "description": "Dictionary-based lemmatizer only",
                "title": "Toggle dictionary-based lemmatize",
                "type": "boolean"
              },
              "lemma_edit": {
                "default": true,
                "description": "Use an edit classifier in addition to seq2seq to make long sentence predictions more stable",
                "title": "Toggle edit classifier",
                "type": "boolean"
              },
              "lemma_beam_size": {
                "default": 1,
                "description": "Control beam size during decoding in seq2seq",
                "title": "Control beam size during decoding in seq2seq",
                "type": "integer",
                "minimum": 1
              },
              "lemma_max_dec_len": {
                "default": 50,
                "description": "Control maximum decoding character length in seq2seq, decoder will stop if this length is achieved and end-of-sequence character still not seen",
                "title": "Control maximum decoding character length in seq2seq",
                "type": "integer",
                "minimum": 1
              }
            },
            "description": "Generates the word lemmas for all words in the Document, dependency: - 'tokenize, mwt, pos'",
            "title": "Stanza lemma",
            "type": "object"
          },
          "stanza_depparse": {
           "properties": {
              "depparse_batch_size": {
                "default": 5000,
                "description": "Maximum number of words to process as minibatch, may require large amounts of RAM; should be set larger than the number of workds in the longest sentence in input document, or may result in unexpected behaviors",
                "title": "Maximum number of words per minibatch",
                "type": "integer",
                "minimum": 1
              },
              "depparse_pretagged": {
                "default": false,
                "description": "Assumes document is tokenized and pretagged, only run dependency parsing",
                "title": "Assume document is pretokenized and pretagged",
                "type": "boolean"
              }
            },
            "description": "Provides an accurate syntactic dependency parsing analysis, dependency: - 'tokenize, mwt, pos, lemma'",
            "title": "Stanza depparse",
            "type": "object"
          },
          "stanza_ner": {
            "properties": {
              "ner_batch_size": {
                "default": 32,
                "description": "Maximum number of sentences to process as minibatch, may require large amounts of RAM",
                "title": "Maximum number of words per minibatch",
                "type": "integer",
                "minimum": 1
            }
          },
          "description": "Recognize named entities for all token spans in the corpus, dependency: - 'tokenize, mwt'",
          "title": "Stanza ner",
          "type": "object"
          },
          "stanza_sentiment": {
            "properties": {
              "batch_size": {
                "anyOf": [
                {
                  "type": "null",
                  "default": null,
                  "title": "Run corpus as one."
                },
                {
                  "type": "integer",
                  "default": 2,
                  "minimum": 2,
                  "title": "Number of chunks:"
                }
              ],
              "title": "Run everything at once (None) or if set to integer, processing is broken into chunks of that size"
              }
            },
            "type": "object"
          },
          "stanza_constituency": {
            "properties": {
              },
              "description": "Parse each sentence in a document using a phrase structure parser, dependency: - 'tokenize, mwt, pos'",
              "title": "Stanza constituenty",
              "type": "object"
            }
          },
          "title": "Stanza",
          "type": "object"
        },
      {
        "properties": {
          "model": {
            "default": "en_core_web_md",
            "description": "Pretrained/trained model to load and use components from. IF model is not installed as package a path to the directory containing the models config.cfg file can be provided.",
            "title": "Selected model:",
            "type": "string",
            "enum": [
              "en_core_web_md",
              "en_core_web_sm"
            ]
          },
          "lang": {
            "default": "en",
            "description": "Language of the text to be annotated to chose model if no specific model is given.",
            "title": "Language:",
            "enum": [
              "en",
              "de"
            ],
            "type": "string"
          },
          "set_device": {
            "default": false,
            "description": "Request job to be run on CPU only (require_CPU), on GPU if available (prefer_GPU), only on GPU (require_GPU, will fail if no GPU), default by false.",
            "title": "Set device?",
            "enum": [
              "prefer_GPU",
              "require_GPU",
              "require_CPU",
              false
            ],
            "type": ["boolean", "string"]
          },
          "config": {
            "properties": {
              "nlp.batch_size": {
                "default": 256,
                "title": "Nlp batch size:",
                "description": "Default batch size for pipe.",
                "type": "integer"
              }
            },
            "description": "Parameters set here are usually defined in a models .cfg file and don't need to be changed.",
            "title": "Configuration parameters",
            "type": "object"
          },
          "processors": {
            "default": [],
            "type": "list",
            "title": "Processors"
            },
          
          "type": {
            "const": "spacy",
            "type": "string"
          }
        },
        "title": "Spacy",
        "type": "object"
      },
      {
        "properties": {
          "filename": {
            "default": "Test",
            "description": "Name of .vrt file to create.",
            "title": "Filename",
            "type": "string"
          },
          "lang": {
            "default": "en",
            "description": "Language code for the language to use",
            "enum": [
              "en",
              "de"
            ],
            "title": "Language",
            "type": "string"
          },
          "job": {
            "type": "array",
            "items": {
              "type": "string",
              "enum": [
                "ner",
                "pos"
              ]
              },
            "title": "Job"
          },
          "type": {
            "const": "flair",
            "type": "string"
          }
        },
        "title": "Flair",
        "type": "object"
      }
    ],
    "title": "Tool to use for annotation:"
    }
  },
  "type": "object"
}
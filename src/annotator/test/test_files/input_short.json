{
    "model": "en_core_web_md",
    "lang": "en",
    "text_type": "news",
    "processors": "tok2vec, senter, tagger, parser, attribute_ruler, lemmatizer, ner",
    "pretrained": false,
    "set_device": false,
    "config": {
        "_nlp.batch_size_comment": "Default batch size for pipe.",
        "nlp.batch_size": 256,
        "_components":{
            "tokenizer": {
                "_tokenizer_comment": "Segment Text, create Doc object with discovered segment bounderies. Reads punctuation and special case rules from Language.Defaults.",
                "_rules_comment": "Exceptions and special-cases for the tokenizer. [Dict[str, List[Dict[int, str]]] e.g. [{ORTH: 'do'}, {ORTH: 'n't', NORM: 'not'}]"
            },
            "attribute_ruler": {
                "_attribute_ruler_comment": "Pipeline component for rule-based token attribute assignment. Trainable: No.",
                "_validate_comment": "Wheter patterns should be validated, Defaults to false.",
                "validate": false
            },
            "parser": {
                "_dependency_parser_comment": "Pipeline component for syntactic dependency parsing, coresponds to DependencyParser. Trainable: Yes.",
                "_moves_comment": "List of transition names. Inferred from data if not provided",
                "moves": null,
                "_model_comment": "Model powering the pipeline component and parameters for model.",
                "_min_action_frequency_comment": "Sets the minimum frequency of labelled actions to retain, affects label accuracy and possibly attachment structure.",
                "_learn_tokens_comment": "Decides whether to learn to merge subtokens split relative to gold standard. Default to false, Experimental.",
                "learn_tokens": false,
                "_update_with_oracle_cut_size_comment": "During training: Cut long sequences into shorter segments by creating intermediate standards based on gold-standard history. Default 100.",
                "update_with_oracle_cut_size": 100
            },
            "entity_linker": {
                "_entity_linker": "Pipeline component for named entity linking and disambiguation. Trainable: Yes. Requires: KnowledgeBase (KB).",
                "_model_comment": "Model powering pipeline component.",
                "_entity_vector_length": "Size of encoding vectors in KB",
                "_labels_discard_comment": "NER labels that will automatically get a 'NIL' prediction, Default []",
                "labels_discard": null,
                "_n_sents_comment": "Number of neighbouring sentences to take into account, Default 0.",
                "n_sents": 0,
                "_incl_prior_comment": "Whether or not to include prior probabilities from the KB in the model.",
                "_incl_context_comment": "Whether or not to include the local context in the model.",
                "_overwrite_comment": "Whether existing annotation is overwritten. Defaults to True.",
                "overwrite": true
            },
            "entity_ruler": {
                "_entity_ruler_comment": "Add spans to entities using token based rules or exact phrase matches. Trainable: No.",
                "_phrase_matcher_attr_comments": "Optional attribute name match on for the internal PhraseMatcher, e.g. LOWER to match on the lowercase token text. Defaults to None.",
                "phrase_matcher_attr" : null,
                "_validate_comment": "Wheter patterns should be validated (passed to Matcher and PhraseMatcher), Default False.",
                "validate": false,
                "_overwrite_ents_comment": "If existing entities are present, e.g. entities added by the model, overwrite them by matches if necessary. Defaults to False.",
                "overwrite_ents": false,
                "_ent_id_sep": "Separator used internally for entity IDs. Defaults to '||'.",
                "ent_id_sep": "||",
                "_patterns_comment": "Optional patterns to load in on initialization. Shape List[Dict[str, Union[str, List[dict]]]] e.g. [{'label': 'ORG', 'pattern': 'Apple'},{'label': 'GPE', 'pattern': [{'lower': 'san'}, {'lower': 'francisco'}]}]" 
            },
            "ner": {
                "_ner_comment": "Pipeline component for transition-based named entity recognition, corresponds to EntityRecognizer. Idejtifies non-overlapping labelled spans of tokens. Trainable: Yes.",
                "_model_comment": "Model powering pipeline component.",
                "_moves_comment": "A list of transition names. Inferred from the data if set to None, which is the default.",
                "moves": null,
                "_update_with_oracle_cut_size_comment": "During training: Cut long sequences into shorter segments by creating intermediate standards based on gold-standard history. Default 100.",
                "update_with_oracle_cut_size": 100,
                "_incorrect_spans_key": "Identifies spans that are known to be incorrect entity annotations. The incorrect entity annotations can be stored in the span group in Doc.spans, under this key. Defaults to None.",
                "incorrect_spans_key": null
            },
            "lemmatizer": {
                "_lemmatizer_comment": "Pipeline component for assignment of base forms to tokens based on POS tags or lookup tables. Trainable: No. Requires: spacy-lookups-data or POS tags",
                "_mode_comment": "Lemmatizer mode, 'lookup' or 'rule'. Lookup needs lookup tables. rule needs coarse-grained POS.",
                "mode": "rule",
                "_overwrite_comment": "Wheter to overwrite existing lemmas. Default False",
                "overwrite": false,
                "_scorer_comment": "Scoring method, Defaults to Scorer.score_token_attr."
            },
            "morphologizer": {
                "_morphologizer_comment": "Pipeline component to predict morphological features and coarse-grained UPOS tags. Trainable: Yes.",
                "_model_comment": "Model to use, defaults to Tagger.",
                "_overwrite_comment": "Whether the values of existing features are overwritten. Defaults to True.",
                "overwrite": true,
                "_extend_comments": "Whether existing feature types (whose values may or may not be overwritten depending on overwrite) are preserved. Defaults to False.",
                "extend": false,
                "_scorer_comment": "Scoring method, Defaults to Scorer.score_token_attr. for attributes 'pos' and 'morph' and Scorer.score_token_attr_per_feat for attribute 'morph'."
            },
            "senter": {
                "_senter_comment": "Pipeline component for sentence segmentation. Trainable: Yes.",
                "_model_comment": "Model powering pipeline component",
                "_overwrite_comment": "Whether existing annotation is overwritten. Defaults to False.",
                "overwrite": false,
                "_scorer_comment": "Scoring method, Defaults to Scorer.score_spans for attribute 'sents'."
            },
            "sentencizer": {
                "_sentencizer_comment": "Simple pipeline component for custom sentence boundary detection logic without dependency parse.",
                "_punct_chars_comment": "Optional custom list of punctuation characters that mark sentence ends. See below for defaults. List[str]",
                "_overwrite_comment": "Whether existing annotation is overwritten. Defaults to False.",
                "overwrite": false,
                "_scorer_comment": "Scoring method, Defaults to Scorer.score_spans for attribute 'sents'."
            },
            "spancat": {
                "_spancat_comment": "Pipeline component for labeling potentially overlapping spans of text. Trainable: Yes.",
                "_model_comment": "Model instance given as list of documents and indices representing candidate span offsets. Predicts probability for each category for each span.",
                "_suggester_comment": "Function that suggests spans, returns spans as ragged array of two integer columns for start and end positions.",
                "_span_key": "Key of Doc.spans dict to save spans under. Looks for spans on reference document under same key during initilization and trianing. Defaul to 'spans'.",
                "span_key": "spans",
                "_threshhold_comment": "Minimum probability to consider a prediciton positive. Defaults to 0.5.",
                "threshhold": 0.5,
                "_max_positive_comment": "Maximum number of labels to consider positive per span. Defaults to None, indicating no limit.",
                "max_positive": null
            },
            "tagger": {
                "_tagger_comment": "Pipeline component for POS tagging. Trainable: Yes.",
                "_model_comment": "Model instance predicting tag probabilities. Output vectors should match number  of tags in size and be normalized as probabilities. Defaults to Tagger.",
                "_overwrite_comment": "Whether existing annotation is overwritten. Defaults to False.",
                "overwrite": false,
                "_scorer_comment": "Scoring method, Defaults to Scorer.score_token_attr. for attribute 'tag'.",
                "_neg_prefix_comment": "The prefix used to specify incorrect tags while training. The tagger will learn not to predict exactly this tag. Defaults to !.",
                "neg_prefix": "!"
            },
            "textcat": {
                "_textcat_comment": "Pipeline component for text classification. predicts categories over a whole document. Use for one specific true label per document. For multi-level classification use textcat_multilabel.",
                "_model_comment": "Thinc Model powering pipeline component",
                "_threshold_comment": "Cutoff to consider a prediction “positive”, relevant when printing accuracy results.",
                "_scorer_comment": "Scoring method, Defaults to Scorer.score_cats for attribute 'cats'."
            },
            "textcat_multilabel": {
                "_textcat_multilevel_comment": "Pipeline component for multi-level classification of tokens into categories.",
                "_model_comment": "Thinc Model powering pipeline component",
                "_threshold_comment": "Cutoff to consider a prediction “positive”, relevant when printing accuracy results.",
                "_scorer_comment": "Scoring method, Defaults to Scorer.score_cats for attribute 'cats'."
            },
            "tok2vec": {
                "_tok2vec_comment": "Token-to-vectore model that sets its output to the Doc.tensor attribute.This is mostly useful to share a single subnetwork between multiple components.",
                "_model_comment": "Model to use, Defaults to HashEmbedCNN."
            },
            "transformer" : {
                "_transformer_comment": "Pipeline component for multi-task learning with transformer models.",
                "_set_extra_annotations_comment": "Function that takes a batch of Doc objects and transformer outputs and stores the annotations on the Doc. The Doc._.trf_data attribute is set prior to calling the callback. By default, no additional annotations are set.",
                "_max_batch_items": "Maximum size of padded batch. Defaults to 128*32"
            }
        }
    }
}
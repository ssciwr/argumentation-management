{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook for annotator package\n",
    "## Scientific Software Center, I. S. Ulusoy, C. Delavier, Heidelberg University\n",
    "*January 2022*\n",
    "\n",
    "In the following the basic functionalities of the package are introduced. We will load basic text in English and German and annotate it using the available features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the modules of the annotator package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import annotator.base as be\n",
    "import annotator.pipe as pe\n",
    "import annotator.mspacy as msp\n",
    "import annotator.mstanza as mst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is passed to the package using a dictionary (json-file). Later, this will be hidden in the user interface. For now, you will load the default dictionary which has all options pre-set to default values, and then replace the options that you specify for your desired processing.\n",
    "\n",
    "### Read the default dictionary - do not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in input.json\n",
    "default_dict = be.prepare_run.load_input_dict(\"input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main input dictionary contains these important parameters:\n",
    "```\n",
    "    \"input\": \"./test/test_files/example_en.txt\",\n",
    "    \"tool\": \"spacy\",\n",
    "    \"corpus_name\": \"test\",\n",
    "    \"language\": \"en\",\n",
    "    \"document_type\": \"text\",\n",
    "    \"processing_option\": \"fast\",\n",
    "    \"processing_type\": \"tokenize\"\n",
    "```\n",
    "You can print these using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(default_dict[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make a copy of the dictionary for your run\n",
    "mydict = dict(default_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tell the programm that the data we want to annotate is stored in `example_en.txt` with path to the file `./test/test_files/` and that we want to use the tool `spacy` to annotate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt the keys for your run\n",
    "You can and *should* change the following options:  \n",
    "```\n",
    "input  \n",
    "language\n",
    "document_type\n",
    "corpus_name\n",
    "processing_option\n",
    "```\n",
    "The following languages are available:\n",
    "1. `fast` option (SpaCy):\n",
    "- `en` (English)\n",
    "- `de` (German)\n",
    "- `fr` (French)\n",
    "- `it` (Italian)\n",
    "- `ja` (Japanese)\n",
    "- `pt` (Portuguese)\n",
    "- `ru` (Russian)\n",
    "- `es` (Spanish)\n",
    "1. `accurate` option (Stanza): All of the above plus  \n",
    "- `ar` (Armenian)\n",
    "- `be` (Belarusian)\n",
    "- `uk` (Ukrainian)\n",
    "\n",
    "\n",
    "\n",
    "Change the content below according to your needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell where to find the input file\n",
    "mydict[\"input\"] = \"./test/test_files/example_de.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell what to name your corpus\n",
    "mydict[\"corpus_name\"] = \"test_de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell the language of the document - currently \"en\" and \"de\" are available\n",
    "mydict[\"language\"] = \"de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell which document type: This will aid in the model selection for some of the tools\n",
    "# (normal text: \"text\", historic text: \"historic\")\n",
    "mydict[\"document_type\"] = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell which option to choose: \"fast\" or \"accurate\" or \"manual\"\n",
    "# this will set the toolchain for the text processing\n",
    "# currently, fast = spacy for all types of processing\n",
    "# accurate = stanza for all types of processing\n",
    "# this will be further adapted\n",
    "# please don\"t use manual for now, it doesn't add anything new\n",
    "mydict[\"processing_option\"] = \"accurate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell what you want to do with the text: Options are\n",
    "# tokenize - separate into tokens\n",
    "# pos - part-of-speech tagging\n",
    "# lemma - lemma\n",
    "mydict[\"processing_type\"] = \"tokenize, pos, lemma\"\n",
    "# currently, tokenize is mandatory, the option for pretokenized text is\n",
    "# not enabled in this version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for JupyterHub - do not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict[\"advanced_options\"][\"output_dir\"] = \"/home/jovyan/shared/test/out/\"\n",
    "mydict[\"advanced_options\"][\"corpus_dir\"] = \"/home/jovyan/shared/corpora/\"\n",
    "mydict[\"advanced_options\"][\"registry_dir\"] = \"/home/jovyan/shared/registry/\"\n",
    "mydict[\"stanza_dict\"][\"dir\"] = \"/home/jovyan/stanza_resources/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the annotation - do not change\n",
    "The below will be hidden behind the user interface, for now you need to execute the cells to perform the annotation. Please do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dictionary is set above, now we need to validate\n",
    "be.prepare_run.validate_input_dict(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the input text to be processed as raw text\n",
    "data = be.prepare_run.get_text(mydict[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the tool dictionaries and options\n",
    "obj = pe.SetConfig(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline\n",
    "# here we select by hand currently\n",
    "if \"spacy\" in obj.tool:\n",
    "    spacy_dict = obj.mydict[\"spacy_dict\"]\n",
    "    pipe = msp.spacy_pipe(spacy_dict)\n",
    "    annotated = pipe.apply_to(data)\n",
    "    annotated.pass_results(\"STR\", mydict, ret=False)\n",
    "elif \"stanza\" in obj.tool:\n",
    "    stanza_dict = obj.mydict[\"stanza_dict\"]\n",
    "    stanza_pipe = mst.MyStanza(stanza_dict)\n",
    "    annotated = stanza_pipe.apply_to(data)\n",
    "    annotated.pass_results(mydict)\n",
    "else:\n",
    "    print(\"Did not find tool to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the newly annotated corpus in cwb via the command-line interface \n",
    "Open a terminal and type \"cqp -e\". All further processing and options are then done via the cqp prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set the registry dir in the cqp terminal  \n",
    "`set Registry \"/home/jovyan/shared/registry\";`\n",
    "1. Display the possible corpora  \n",
    "`show;`\n",
    "1. Show information about corpus\n",
    "`info TEST_DE;`\n",
    "1. Load the corpus  \n",
    "`TEST_DE;`\n",
    "1. Parse for words  \n",
    "`ist;`\n",
    "1. Search for POS  \n",
    "`[POS = 'NN']`\n",
    "1. Search for lemma  \n",
    "`[lemma = 'sein']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "248d8c9983699a243ff8e6a68a4f537cc73e09b2b8d6acc84fd600ae9279441d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc35833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15e780",
   "metadata": {},
   "source": [
    "Installing stanza takes ages. There are google colab notebooks available that document the usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3aae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an English model into the default directory\n",
    "print(\"Downloading English model...\")\n",
    "stanza.download(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def418b",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "Stanza offers pipelines similarly to spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an English pipeline, with all processors by default\n",
    "print(\"Building an English pipeline...\")\n",
    "en_nlp = stanza.Pipeline(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e5c4f",
   "metadata": {},
   "source": [
    "# Sentencize, Tokenize, Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing English text\n",
    "en_doc = en_nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "for i, sent in enumerate(en_doc.sentences):\n",
    "    print(\"[Sentence {}]\".format(i + 1))\n",
    "    for word in sent.words:\n",
    "        print(\n",
    "            \"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\n",
    "                word.text, word.lemma, word.pos, word.head, word.deprel\n",
    "            )\n",
    "        )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f63567",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize\")\n",
    "doc = nlp(\"This is a test sentence for stanza. This is another sentence.\")\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(f\"====== Sentence {i+1} tokens =======\")\n",
    "    print(\n",
    "        *[f\"id: {token.id}\\ttext: {token.text}\" for token in sentence.tokens], sep=\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82db386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([sentence.text for sentence in doc.sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdead077",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize\", tokenize_no_ssplit=True)\n",
    "doc = nlp(\"This is a sentence.\\n\\nThis is a second. This is a third.\")\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(f\"====== Sentence {i+1} tokens =======\")\n",
    "    print(\n",
    "        *[f\"id: {token.id}\\ttext: {token.text}\" for token in sentence.tokens], sep=\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda0846",
   "metadata": {},
   "source": [
    "## Can also use spaCy for english tokenization in its pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea74e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    lang=\"en\", processors={\"tokenize\": \"spacy\"}\n",
    ")  # spaCy tokenizer is currently only allowed in English pipeline.\n",
    "doc = nlp(\"This is a test sentence for stanza. This is another sentence.\")\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(f\"====== Sentence {i+1} tokens =======\")\n",
    "    print(\n",
    "        *[f\"id: {token.id}\\ttext: {token.text}\" for token in sentence.tokens], sep=\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    lang=\"en\", processors=\"tokenize,mwt,pos,lemma\"\n",
    ")  # the warning about mwt ('multi-word token') will be\n",
    "# triggered in English and Chinese, for example, that\n",
    "# do not have mwt\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
    "print(\n",
    "    *[\n",
    "        f'word: {word.text+\" \"}\\tlemma: {word.lemma}'\n",
    "        for sent in doc.sentences\n",
    "        for word in sent.words\n",
    "    ],\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092bafe",
   "metadata": {},
   "source": [
    "Lemmatizer can be improved by loading specific dictionary that the user provides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ec960",
   "metadata": {},
   "source": [
    "# Part-of-speech, morphological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849547be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac84e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748cc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20835ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d01d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5a679c",
   "metadata": {},
   "source": [
    "# Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14480523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f66a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d6676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6abc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924f059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fc406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56316b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b44216ef",
   "metadata": {},
   "source": [
    "# Constituency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63777c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce83ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93742b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445d363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a000ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba785f6b",
   "metadata": {},
   "source": [
    "# Named entities\n",
    "\n",
    "Utilize entity recognition (NER) module to identify spans of particular entity type. Running the [NERProcessor](https://stanfordnlp.github.io/stanza/ner.html) requires the [TokenizeProcessor](https://stanfordnlp.github.io/stanza/tokenize.html). After the pipeline was run the named entities can be accessed via Doc.ents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "path = \"../data/Original/iued_test_original.txt\"\n",
    "\n",
    "with open(path, \"r\") as file:\n",
    "    data = file.read().replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize, ner\")\n",
    "doc = nlp(data)\n",
    "print(*[\"entity:{} \\ttype:{}\".format(ent.text, ent.type) for ent in doc.ents], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entities_stanza(doc):\n",
    "\n",
    "    named_entities = defaultdict(list)\n",
    "\n",
    "    for i, ent in enumerate(doc.ents):\n",
    "        # add the entities label, start index and end index to the dictionary\n",
    "        named_entities[\"Text: {} |Label: {}\".format(ent.text, ent.type)].append(\n",
    "            [ent.start_char, ent.end_char, i]\n",
    "        )\n",
    "\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302eabba",
   "metadata": {},
   "source": [
    "Stanza doesnt seem to support the labeling using a corpus wide indexing, instead giving the found entity tokens Ids based\n",
    "on their position in their respective sentence. So using the definite start and end chars seems more appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a50aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_ent = named_entities_stanza(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18428dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(named_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in named_ent[\"Text: Audi |Label: ORG\"]:\n",
    "    print(data[elem[0] - 20 : elem[1] + 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67148622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
